{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 %spark2.pyspark\
\
# USING WORD to VEC AS TRANSFORMER\
\
from pyspark.ml import Pipeline\
from pyspark.ml.classification import LogisticRegression\
from pyspark.ml.regression import LinearRegression\
from pyspark.ml.feature import HashingTF, Tokenizer, Word2Vec\
from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType\
\
schema = StructType([StructField('id', IntegerType(), True),StructField('product_uid', IntegerType(), True),StructField('product_title', StringType(), True),StructField('search_term', StringType(), True),StructField('relevance', IntegerType(), True)])\
path = "/tmp/train.csv"\
oritraindata = spark.read.csv("/tmp/train.csv", header=True, mode="DROPMALFORMED", schema=schema)\
traindata2 = oritraindata.select("product_uid", "search_term", "relevance").limit(10000)\
traindata = traindata2.selectExpr("product_uid as product_uid", "search_term as search_term", "relevance as label")\
\
\
# Configure an ML pipeline, which consists of one stages: tokenizer, word2vec, hashingTF and lr.\
tokenizer = Tokenizer(inputCol="search_term", outputCol="words")\
word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol="words", outputCol="features")\
lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\
\
pipeline = Pipeline(stages=[tokenizer, word2Vec,lr])\
\
# Fit the pipeline to training documents.\
model = pipeline.fit(traindata)\
\
rescaledData = model.transform(traindata)\
rescaledData.select("prediction", "features").show()\
\
\
# Prepare test documents, which are unlabeled (id, text) tuples.\
schema2 = StructType([StructField('id', IntegerType(), True),StructField('product_uid', IntegerType(), True),StructField('product_title', StringType(), True),StructField('search_term', StringType(), True)])\
oritestdata = spark.read.csv("/tmp/test.csv", header=True, mode="DROPMALFORMED", schema=schema2)\
testdata = oritestdata.select("product_uid", "search_term").limit(100)\
\
\
# Make predictions on test documents and print columns of interest.\
prediction = model.transform(testdata)\
print("\\n\\nshowing results on test data\\n")\
prediction.select("prediction", "features").show()\
'''\
selected = prediction.select("product_uid", "search_term", "prediction")\
for row in selected.collect():\
    rid, text, prediction = row\
    print("(%d, %s) --> prediction=%f" % (rid, text, prediction))\
\
'''\
# Print the coefficients and intercept for linear regression\
print("Coefficients: %s" % str(model.stages[-1].coefficients))\
print("Intercept: %s" % str(model.stages[-1].intercept))\
\
}